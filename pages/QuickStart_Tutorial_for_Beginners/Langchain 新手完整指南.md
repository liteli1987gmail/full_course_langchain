
# Langchain æ–°æ‰‹å®Œæ•´æŒ‡å—

Langchain å¯èƒ½æ˜¯ç›®å‰åœ¨ AI é¢†åŸŸä¸­æœ€çƒ­é—¨çš„äº‹ç‰©ä¹‹ä¸€ï¼Œä»…æ¬¡äºå‘é‡æ•°æ®åº“ã€‚

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181142.png")

å®ƒæ˜¯ä¸€ä¸ªæ¡†æ¶ï¼Œç”¨äºåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šå¼€å‘åº”ç”¨ç¨‹åºï¼Œä¾‹å¦‚ GPTã€LLamaã€Hugging Face æ¨¡å‹ç­‰ã€‚

å®ƒæœ€åˆæ˜¯ä¸€ä¸ª Python åŒ…ï¼Œä½†ç°åœ¨ä¹Ÿæœ‰ä¸€ä¸ª TypeScript ç‰ˆæœ¬ï¼Œåœ¨åŠŸèƒ½ä¸Šé€æ¸èµ¶ä¸Šï¼Œå¹¶ä¸”è¿˜æœ‰ä¸€ä¸ªåˆšåˆšå¼€å§‹çš„ Ruby ç‰ˆæœ¬ã€‚

### ä¸ºä»€ä¹ˆéœ€è¦ Langchainï¼Ÿ

ä½†æ˜¯ï¼Œä¸ºä»€ä¹ˆé¦–å…ˆéœ€è¦å®ƒå‘¢ï¼Ÿæˆ‘ä»¬æ˜¯å¦å¯ä»¥ç®€å•åœ°å‘é€ä¸€ä¸ª API è¯·æ±‚æˆ–æ¨¡å‹ï¼Œç„¶åå°±å¯ä»¥ç»“æŸäº†ï¼Ÿä½ æ˜¯å¯¹çš„ï¼Œå¯¹äºç®€å•çš„åº”ç”¨ç¨‹åºè¿™æ ·åšæ˜¯å¯è¡Œçš„ã€‚

ä½†æ˜¯ï¼Œä¸€æ—¦æ‚¨å¼€å§‹å¢åŠ å¤æ‚æ€§ï¼Œæ¯”å¦‚å°†è¯­è¨€æ¨¡å‹ä¸æ‚¨è‡ªå·±çš„æ•°æ®ï¼ˆå¦‚ Google Analyticsã€Stripeã€SQLã€PDFã€CSV ç­‰ï¼‰è¿æ¥èµ·æ¥ï¼Œæˆ–è€…ä½¿è¯­è¨€æ¨¡å‹æ‰§è¡Œä¸€äº›æ“ä½œï¼Œæ¯”å¦‚å‘é€ç”µå­é‚®ä»¶ã€æœç´¢ç½‘ç»œæˆ–åœ¨ç»ˆç«¯ä¸­è¿è¡Œä»£ç ï¼Œäº‹æƒ…å°±ä¼šå˜å¾—æ··ä¹±å’Œé‡å¤ã€‚

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181307.png")

LangChain é€šè¿‡ç»„ä»¶æä¾›äº†è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ–‡æ¡£åŠ è½½å™¨ä» PDFã€Stripe ç­‰æ¥æºåŠ è½½æ•°æ®ï¼Œç„¶ååœ¨å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­ä¹‹å‰ï¼Œå¯ä»¥é€‰æ‹©ä½¿ç”¨æ–‡æœ¬åˆ†å‰²å™¨å°†å…¶åˆ†å—ã€‚åœ¨è¿è¡Œæ—¶ï¼Œå¯ä»¥å°†æ•°æ®æ³¨å…¥åˆ°æç¤ºæ¨¡æ¿ä¸­ï¼Œç„¶åä½œä¸ºè¾“å…¥å‘é€ç»™æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨å·¥å…·æ‰§è¡Œä¸€äº›æ“ä½œï¼Œä¾‹å¦‚ä½¿ç”¨è¾“å‡ºå†…å®¹å‘é€ç”µå­é‚®ä»¶ã€‚

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181255.png")

å®é™…ä¸Šï¼Œè¿™äº› **æŠ½è±¡** æ„å‘³ç€æ‚¨å¯ä»¥è½»æ¾åœ°åˆ‡æ¢åˆ°å¦ä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œä»¥èŠ‚çº¦æˆæœ¬æˆ–äº«å—å…¶ä»–åŠŸèƒ½ï¼Œæµ‹è¯•å¦ä¸€ä¸ªå‘é‡æ•°æ®åº“çš„åŠŸèƒ½ï¼Œæˆ–è€…æ‘„å–å¦ä¸€ä¸ªæ•°æ®æºï¼Œåªéœ€å‡ è¡Œä»£ç å³å¯å®ç°ã€‚é“¾ï¼ˆchainsï¼‰æ˜¯å®ç°è¿™ä¸€é­”æ³•çš„æ–¹å¼ï¼Œæˆ‘ä»¬å°†ç»„ä»¶é“¾æ¥åœ¨ä¸€èµ·ï¼Œä»¥å®Œæˆç‰¹å®šä»»åŠ¡ã€‚è€Œä»£ç†ï¼ˆagentsï¼‰åˆ™æ›´åŠ æŠ½è±¡ï¼Œé¦–å…ˆè€ƒè™‘ä½¿ç”¨è¯­è¨€æ¨¡å‹æ¥æ€è€ƒå®ƒä»¬éœ€è¦åšä»€ä¹ˆï¼Œç„¶åä½¿ç”¨å·¥å…·ç­‰æ–¹å¼æ¥å®ç°ã€‚

å¦‚æœæ‚¨å¯¹å°†è¯­è¨€æ¨¡å‹ä¸è‡ªå·±çš„æ•°æ®å’Œå¤–éƒ¨ä¸–ç•Œè¿æ¥çš„å¼ºå¤§ä¹‹å¤„æ„Ÿå…´è¶£ï¼Œå¯ä»¥æŸ¥çœ‹ä¸ LangChain å‘å¸ƒæ—¶é—´ç›¸è¿‘çš„ç ”ç©¶è®ºæ–‡ï¼Œä¾‹å¦‚ Self-Askã€With Search å’Œ ReActã€‚

## æ–°æ‰‹åº”è¯¥äº†è§£å“ªäº›æ¨¡å—ï¼Ÿ

ç°åœ¨è®©æˆ‘ä»¬æ¥çœ‹çœ‹å¹•åçš„çœŸå®æƒ…å†µã€‚ç›®å‰æœ‰ä¸ƒä¸ªæ¨¡å—åœ¨ LangChain ä¸­æä¾›ï¼Œæ–°æ‰‹åº”è¯¥äº†è§£è¿™äº›æ¨¡å—ï¼ŒåŒ…æ‹¬æ¨¡å‹ï¼ˆmodelsï¼‰ã€æç¤ºï¼ˆpromptsï¼‰ã€ç´¢å¼•ï¼ˆindexesï¼‰ã€å†…å­˜ï¼ˆmemoryï¼‰ã€é“¾ï¼ˆchainsï¼‰å’Œä»£ç†ï¼ˆagentsï¼‰ã€‚

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181318.png")

###  æ ¸å¿ƒæ¨¡å—çš„æ¦‚è¿°

æ¨¡å‹åœ¨é«˜å±‚æ¬¡ä¸Šæœ‰ä¸¤ç§ä¸åŒç±»å‹çš„æ¨¡å‹ï¼šè¯­è¨€æ¨¡å‹ï¼ˆlanguage modelsï¼‰å’Œæ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼ˆtext embedding modelsï¼‰ã€‚åµŒå…¥æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—æ•°ç»„ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥å°†æ–‡æœ¬è§†ä¸ºå‘é‡ç©ºé—´ã€‚
![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181356.png")

åœ¨è¿™ä¸ªå›¾åƒä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åœ¨ä¸€ä¸ªäºŒç»´ç©ºé—´ä¸­ï¼Œâ€œmanâ€æ˜¯â€œkingâ€ï¼Œâ€œwomanâ€æ˜¯â€œqueenâ€ï¼Œå®ƒä»¬ä»£è¡¨ä¸åŒçš„äº‹ç‰©ï¼Œä½†æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€ç§æ¨¡å¼ã€‚è¿™ä½¿å¾—è¯­ä¹‰æœç´¢æˆä¸ºå¯èƒ½ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å‘é‡ç©ºé—´ä¸­å¯»æ‰¾æœ€ç›¸ä¼¼çš„æ–‡æœ¬ç‰‡æ®µï¼Œä»¥æ»¡è¶³ç»™å®šçš„è®ºç‚¹ã€‚

ä¾‹å¦‚ï¼ŒOpenAI çš„æ–‡æœ¬åµŒå…¥æ¨¡å‹å¯ä»¥ç²¾ç¡®åœ°åµŒå…¥å¤§æ®µæ–‡æœ¬ï¼Œå…·ä½“è€Œè¨€ï¼Œ8100 ä¸ªæ ‡è®°ï¼Œæ ¹æ®å®ƒä»¬çš„è¯å¯¹æ ‡è®°æ¯”ä¾‹ 0.75ï¼Œå¤§çº¦å¯ä»¥å¤„ç† 6143 ä¸ªå•è¯ã€‚å®ƒè¾“å‡º 1536 ç»´çš„å‘é‡ã€‚

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181417.png")

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ LangChain ä¸å¤šä¸ªåµŒå…¥æä¾›è€…è¿›è¡Œæ¥å£äº¤äº’ï¼Œä¾‹å¦‚ OpenAI å’Œ Cohere çš„ APIï¼Œä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ä½¿ç”¨ Hugging Faces çš„å¼€æºåµŒå…¥åœ¨æœ¬åœ°è¿è¡Œï¼Œä»¥è¾¾åˆ° **å…è´¹å’Œæ•°æ®éšç§** çš„ç›®çš„ã€‚

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181431.png")

ç°åœ¨ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»…å››è¡Œä»£ç åœ¨è‡ªå·±çš„è®¡ç®—æœºä¸Šåˆ›å»ºè‡ªå·±çš„åµŒå…¥ã€‚ä½†æ˜¯ï¼Œç»´åº¦æ•°é‡å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒï¼ŒåµŒå…¥çš„è´¨é‡å¯èƒ½ä¼šè¾ƒä½ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´æ£€ç´¢ä¸å¤ªå‡†ç¡®ã€‚

##  LLMs å’Œ Chat Models

æ¥ä¸‹æ¥æ˜¯è¯­è¨€æ¨¡å‹ï¼Œå®ƒæœ‰ä¸¤ç§ä¸åŒçš„å­ç±»å‹ï¼šLLMs å’Œ Chat Modelsã€‚LLMs å°è£…äº†æ¥å—æ–‡æœ¬è¾“å…¥å¹¶è¿”å›æ–‡æœ¬è¾“å‡ºçš„ APIï¼Œè€Œ Chat Models å°è£…äº†æ¥å—èŠå¤©æ¶ˆæ¯è¾“å…¥å¹¶è¿”å›èŠå¤©æ¶ˆæ¯è¾“å‡ºçš„æ¨¡å‹ã€‚å°½ç®¡å®ƒä»¬ä¹‹é—´å­˜åœ¨ç»†å¾®å·®åˆ«ï¼Œä½†ä½¿ç”¨å®ƒä»¬çš„æ¥å£æ˜¯ç›¸åŒçš„ã€‚æˆ‘ä»¬å¯ä»¥å¯¼å…¥è¿™ä¸¤ä¸ªç±»ï¼Œå®ä¾‹åŒ–å®ƒä»¬ï¼Œç„¶ååœ¨è¿™ä¸¤ä¸ªç±»ä¸Šä½¿ç”¨ predict å‡½æ•°å¹¶è§‚å¯Ÿå®ƒä»¬ä¹‹é—´çš„åŒºåˆ«ã€‚ä½†æ˜¯ï¼Œæ‚¨å¯èƒ½ä¸ä¼šç›´æ¥å°†æ–‡æœ¬ä¼ é€’ç»™æ¨¡å‹ï¼Œè€Œæ˜¯ä½¿ç”¨æç¤ºï¼ˆpromptsï¼‰ã€‚

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181528.png")


##  æç¤ºï¼ˆpromptsï¼‰

æç¤ºï¼ˆpromptsï¼‰æ˜¯æŒ‡æ¨¡å‹çš„è¾“å…¥ã€‚æˆ‘ä»¬é€šå¸¸å¸Œæœ›å…·æœ‰æ¯”ç¡¬ç¼–ç çš„å­—ç¬¦ä¸²æ›´çµæ´»çš„æ–¹å¼ï¼ŒLangChain æä¾›äº† Prompt Template ç±»æ¥æ„å»ºä½¿ç”¨å¤šä¸ªå€¼çš„æç¤ºã€‚æç¤ºçš„é‡è¦æ¦‚å¿µåŒ…æ‹¬æç¤ºæ¨¡æ¿ã€è¾“å‡ºè§£æå™¨ã€ç¤ºä¾‹é€‰æ‹©å™¨å’ŒèŠå¤©æç¤ºæ¨¡æ¿ã€‚

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181528.png")

###  æç¤ºæ¨¡æ¿ï¼ˆPromptTemplateï¼‰
æç¤ºæ¨¡æ¿æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œé¦–å…ˆéœ€è¦åˆ›å»ºä¸€ä¸ª Prompt Template å¯¹è±¡ã€‚æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œä¸€ç§æ˜¯å¯¼å…¥ Prompt Templateï¼Œç„¶åä½¿ç”¨æ„é€ å‡½æ•°æŒ‡å®šä¸€ä¸ªåŒ…å«è¾“å…¥å˜é‡çš„æ•°ç»„ï¼Œå¹¶å°†å®ƒä»¬æ”¾åœ¨èŠ±æ‹¬å·ä¸­çš„æ¨¡æ¿å­—ç¬¦ä¸²ä¸­ã€‚å¦‚æœæ‚¨æ„Ÿåˆ°éº»çƒ¦ï¼Œè¿˜å¯ä»¥ä½¿ç”¨æ¨¡æ¿çš„è¾…åŠ©æ–¹æ³•ï¼Œä»¥ä¾¿ä¸å¿…æ˜¾å¼æŒ‡å®šè¾“å…¥å˜é‡ã€‚

æ— è®ºå“ªç§æƒ…å†µï¼Œæ‚¨éƒ½å¯ä»¥é€šè¿‡å‘Šè¯‰å®ƒè¦æ›¿æ¢å ä½ç¬¦çš„å€¼æ¥æ ¼å¼åŒ–æç¤ºã€‚

åœ¨å†…éƒ¨ï¼Œé»˜è®¤æƒ…å†µä¸‹å®ƒä½¿ç”¨ F å­—ç¬¦ä¸²æ¥æ ¼å¼åŒ–æç¤ºï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨ Ginger 2ã€‚

ä½†æ˜¯ï¼Œä¸ºä»€ä¹ˆä¸ç›´æ¥ä½¿ç”¨ F å­—ç¬¦ä¸²å‘¢ï¼Ÿæç¤ºæé«˜äº†å¯è¯»æ€§ï¼Œä¸å…¶ä½™ç”Ÿæ€ç³»ç»Ÿå¾ˆå¥½åœ°é…åˆï¼Œå¹¶æ”¯æŒå¸¸è§ç”¨ä¾‹ï¼Œå¦‚ Few Shot Learning æˆ–è¾“å‡ºè§£æã€‚

Few Shot Learning æ„å‘³ç€æˆ‘ä»¬ç»™æç¤ºæä¾›ä¸€äº›ç¤ºä¾‹æ¥æŒ‡å¯¼å…¶è¾“å‡ºã€‚
![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181613.png")

è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹?é¦–å…ˆï¼Œåˆ›å»ºä¸€ä¸ªåŒ…å«å‡ ä¸ªç¤ºä¾‹çš„åˆ—è¡¨ã€‚
```python
from langchain import PromptTemplate, FewShotPromptTemplate

examples = [
    {"word": "happy", "antonym": "sad"},
    {"word": "tall", "antonym": "short"},
]

```

ç„¶åï¼Œæˆ‘ä»¬æŒ‡å®šç”¨äºæ ¼å¼åŒ–æä¾›çš„æ¯ä¸ªç¤ºä¾‹çš„æ¨¡æ¿ã€‚

```python
example_formatter_template = """Word: {word}
Antonym: {antonym}
"""

example_prompt = PromptTemplate(
    input_variables=["word", "antonym"],
    template=example_formatter_template,
)
"""
```

æœ€åï¼Œæˆ‘ä»¬åˆ›å»º Few Shot Prompt Template å¯¹è±¡ï¼Œä¼ å…¥ç¤ºä¾‹ã€ç¤ºä¾‹æ ¼å¼åŒ–å™¨ã€å‰ç¼€ã€å‘½ä»¤å’Œåç¼€ï¼Œè¿™äº›éƒ½æ—¨åœ¨æŒ‡å¯¼ LLM çš„è¾“å‡ºã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥æä¾›è¾“å…¥å˜é‡ `examples`, `example_prompt` å’Œåˆ†éš”ç¬¦ `example_separator="\n"`ï¼Œç”¨äºå°†ç¤ºä¾‹ä¸å‰ç¼€ `prefix` å’Œåç¼€ `suffix` åˆ†å¼€ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥ç”Ÿæˆä¸€ä¸ªæç¤ºï¼Œå®ƒçœ‹èµ·æ¥åƒè¿™æ ·ã€‚
```python
few_shot_prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
    prefix="Give the antonym of every input\n",
    suffix="Word: {input}\nAntonym: ",
    input_variables=["input"],
    example_separator="\n",
)

print(few_shot_prompt.format(input="big"))
```

è¿™æ˜¯ä¸€ç§éå¸¸æœ‰ç”¨çš„èŒƒä¾‹ï¼Œå¯ä»¥æ§åˆ¶ LLM çš„è¾“å‡ºå¹¶å¼•å¯¼å…¶å“åº”ã€‚


###  è¾“å‡ºè§£æå™¨ï¼ˆoutput_parsersï¼‰

ç±»ä¼¼åœ°ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦ä½¿ç”¨è¾“å‡ºè§£æå™¨ï¼Œå®ƒä¼šè‡ªåŠ¨å°†è¯­è¨€æ¨¡å‹çš„è¾“å‡ºè§£æä¸ºå¯¹è±¡ã€‚è¿™éœ€è¦æ›´å¤æ‚ä¸€äº›ï¼Œä½†éå¸¸æœ‰ç”¨ï¼Œå¯ä»¥å°† LLM çš„éšæœºè¾“å‡ºç»“æ„åŒ–ã€‚

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181657.png")

å‡è®¾æˆ‘ä»¬æƒ³è¦ä½¿ç”¨ OpenAI åˆ›å»ºç¬‘è¯å¯¹è±¡ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰æˆ‘ä»¬çš„ Joke ç±»ä»¥æ›´å…·ä½“åœ°è¯´æ˜ç¬‘è¯çš„è®¾ç½®å’Œç»“å°¾ã€‚æˆ‘ä»¬æ·»åŠ æè¿°ä»¥å¸®åŠ©è¯­è¨€æ¨¡å‹ç†è§£å®ƒä»¬çš„å«ä¹‰ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥è®¾ç½®ä¸€ä¸ªè§£æå™¨ï¼Œå‘Šè¯‰å®ƒä½¿ç”¨æˆ‘ä»¬çš„ Joke ç±»è¿›è¡Œè§£æã€‚

æˆ‘ä»¬ä½¿ç”¨æœ€å¼ºå¤§ä¸”æ¨èçš„ Pydantic è¾“å‡ºè§£æå™¨ï¼Œç„¶ååˆ›å»ºæˆ‘ä»¬çš„æç¤ºæ¨¡æ¿ã€‚

```python
from langchain.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field


class Joke(BaseModel):
    setup: str = Field(description="question to set up a joke")
    punchline: str = Field(description="answer to resolve the joke")


parser = PydanticOutputParser(pydantic_object=Joke)
```


è®©æˆ‘ä»¬ä¼ é€’æ¨¡æ¿å­—ç¬¦ä¸²å’Œè¾“å…¥å˜é‡ï¼Œå¹¶ä½¿ç”¨éƒ¨åˆ†å˜é‡å­—æ®µå°†è§£ææŒ‡ä»¤æ³¨å…¥åˆ°æç¤ºæ¨¡æ¿ä¸­ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥è¦æ±‚ LLM ç»™æˆ‘ä»¬è®²ä¸€ä¸ªç¬‘è¯ã€‚

ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»å‡†å¤‡å¥½å‘é€å®ƒç»™ OpenAI çš„æ“ä½œæ˜¯è¿™æ ·çš„ï¼šé¦–å…ˆä»æˆ‘ä»¬çš„.env æ–‡ä»¶ä¸­åŠ è½½ OpenAI çš„ API å¯†é’¥ï¼Œç„¶åå®ä¾‹åŒ–æ¨¡å‹ï¼Œè°ƒç”¨å…¶è°ƒç”¨æ–¹æ³•ï¼Œå¹¶ä½¿ç”¨æˆ‘ä»¬å®ä¾‹åŒ–çš„è§£æå™¨è§£ææ¨¡å‹çš„è¾“å‡ºã€‚

```python
from langchain.llms import OpenAI
from dotenv import load_dotenv


load_dotenv()
model = OpenAI(model_name="text-davinci-003", temperature=0.0)
```



ç„¶åï¼Œæˆ‘ä»¬å°±æ‹¥æœ‰äº†æˆ‘ä»¬å®šä¹‰äº†è®¾ç½®å’Œç»“å°¾çš„ç¬‘è¯å¯¹è±¡ã€‚ç”Ÿæˆçš„æç¤ºéå¸¸å¤æ‚ï¼Œå»ºè®®æŸ¥çœ‹ GitHub ä»¥äº†è§£æ›´å¤šä¿¡æ¯ã€‚

```python
prompt = PromptTemplate(
    template="Answer the user query.\n{format_instructions}\n{query}\n",
    input_variables=["query"],
    partial_variables={"format_instructions": parser.get_format_instructions()},
)

joke_query = "Tell me a joke."
formatted_prompt = prompt.format_prompt(query=joke_query)

print(formatted_prompt.to_string())
```
æ‰“å°çš„ç»“æœæ˜¯ï¼š

```text
Answer the user query.
The output should be formatted as a JSON instance 
that conforms to the JSON schema below.

As an example, for the schema
{
    "properties": {
        "foo": {
            "title": "Foo",
            "description": "a list of strings",
            "type": "array",
            "items": {
                "type": "string"
            }
        }
    },
    "required": [
        "foo"
    ]
} 
the object {"foo": ["bar", "baz"]} is a well-formatted 
instance of the schema. 
The object {"properties": {"foo": ["bar", "baz"]}} is 
not well-formatted.

Here is the output schema:
```
{
    "properties": {
        "setup": {
            "title": "Setup",
            "description": "question to set up a joke",
            "type": "string"
        },
        "punchline": {
            "title": "Punchline",
            "description": "answer to resolve the joke",
            "type": "string"
        }
    },
    "required": [
        "setup",
        "punchline"
    ]
}
```
Tell me a joke.
"""
```

æˆ‘ä»¬ç»™ model ä¼ å…¥ prompt æ¨¡æ¿ï¼Œå¹¶ä¸”ç”¨è¾“å‡ºè§£æå™¨è§£æç»“æœï¼š

```python
output = model(formatted_prompt.to_string())
parsed_joke = parser.parse(output)
print(parsed_joke)
```

æˆ‘ä»¬ä¹‹å‰è®²è¿‡ Few Shot Prompt å­¦ä¹ ï¼Œæˆ‘ä»¬ä¼ é€’ä¸€äº›ç¤ºä¾‹æ¥æ˜¾ç¤ºæ¨¡å‹å¯¹æŸç§ç±»å‹çš„æŸ¥è¯¢çš„é¢„æœŸç­”æ¡ˆã€‚æˆ‘ä»¬å¯èƒ½æœ‰è®¸å¤šè¿™æ ·çš„ç¤ºä¾‹ï¼Œæˆ‘ä»¬ä¸å¯èƒ½å…¨éƒ¨é€‚åº”å®ƒä»¬ã€‚è€Œä¸”ï¼Œè¿™å¯èƒ½å¾ˆå¿«å°±ä¼šå˜å¾—éå¸¸æ˜‚è´µã€‚è¿™å°±æ˜¯ç¤ºä¾‹é€‰æ‹©å™¨å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚


###  ç¤ºä¾‹é€‰æ‹©å™¨ï¼ˆexample_selectorï¼‰

ä¸ºäº†ä¿æŒæç¤ºçš„æˆæœ¬ç›¸å¯¹æ’å®šï¼Œæˆ‘ä»¬å°†ä½¿ç”¨åŸºäºé•¿åº¦çš„ç¤ºä¾‹é€‰æ‹©å™¨ `LengthBasedExampleSelector`ã€‚å°±åƒä»¥å‰ä¸€æ ·ï¼Œæˆ‘ä»¬æŒ‡å®šä¸€ä¸ªç¤ºä¾‹æç¤ºã€‚è¿™å®šä¹‰äº†æ¯ä¸ªç¤ºä¾‹å°†å¦‚ä½•æ ¼å¼åŒ–ã€‚æˆ‘ä»¬ç­–å±•ä¸€ä¸ªé€‰æ‹©å™¨ï¼Œä¼ å…¥ç¤ºä¾‹ï¼Œç„¶åæ˜¯æœ€å¤§é•¿åº¦ã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼Œé•¿åº¦æŒ‡çš„æ˜¯æ ¼å¼åŒ–å™¨ç¤ºä¾‹éƒ¨åˆ†çš„æç¤ºä½¿ç”¨çš„å•è¯å’Œæ–°è¡Œçš„æ•°é‡ `max_length`ã€‚


```python
from langchain.prompts import PromptTemplate
from langchain.prompts import FewShotPromptTemplate
from langchain.prompts.example_selector import LengthBasedExampleSelector

examples = [
    {"word": "happy", "antonym": "sad"},
    {"word": "tall", "antonym": "short"},
    {"word": "energetic", "antonym": "lethargic"},
    {"word": "sunny", "antonym": "gloomy"},
    {"word": "windy", "antonym": "calm"},
]

example_prompt = PromptTemplate(
    input_variables=["word", "antonym"],
    template="Word: {word}\nAntonym: {antonym}",
)

example_selector = LengthBasedExampleSelector(
    examples=examples, 
    example_prompt=example_prompt, 
    max_length=25,
)

dynamic_prompt = FewShotPromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix="Give the antonym of every input",
    suffix="Word: {adjective}\nAntonym:", 
    input_variables=["adjective"],
)

print(dynamic_prompt.format(adjective="big"))
```

é‚£ä¹ˆï¼Œä¸èŠå¤©æ¨¡å‹äº’åŠ¨å¦‚ä½•å‘¢ï¼Ÿè¿™å°±å¼•å‡ºäº†æˆ‘ä»¬ä¹‹å‰æåˆ°çš„èŠå¤©æç¤ºæ¨¡æ¿ã€‚èŠå¤©æ¨¡å‹ä»¥èŠå¤©æ¶ˆæ¯åˆ—è¡¨ä¸ºè¾“å…¥ã€‚è¿™ä¸ªåˆ—è¡¨è¢«ç§°ä¸ºæç¤ºã€‚å®ƒä»¬çš„ä¸åŒä¹‹å¤„åœ¨äºï¼Œæ¯æ¡æ¶ˆæ¯éƒ½è¢«é¢„å…ˆé™„åŠ äº†ä¸€ä¸ªè§’è‰²ï¼Œè¦ä¹ˆæ˜¯ AIï¼Œè¦ä¹ˆæ˜¯äººç±»ï¼Œè¦ä¹ˆæ˜¯ç³»ç»Ÿã€‚æ¨¡å‹åº”ç´§å¯†éµå¾ªç³»ç»Ÿæ¶ˆæ¯çš„æŒ‡ç¤ºã€‚ä¸€å¼€å§‹åªæœ‰ä¸€ä¸ªç³»ç»Ÿæ¶ˆæ¯ï¼Œæœ‰æ—¶å®ƒå¯èƒ½å¬èµ·æ¥ç›¸å½“å‚¬çœ ã€‚â€œä½ æ˜¯ä¸€ä¸ªå–„è‰¯çš„å®¢æœä»£ç†äººï¼Œå¯¹å®¢æˆ·çš„é—®é¢˜åšå‡ºé€æ¸çš„å›åº”â€â€¦â€¦ç±»ä¼¼äºè¿™æ ·ï¼Œå‘Šè¯‰èŠå¤©æœºå™¨äººå¦‚ä½•è¡Œäº‹ã€‚AI æ¶ˆæ¯æ˜¯æ¥è‡ªæ¨¡å‹çš„æ¶ˆæ¯ï¼Œäººç±»æ¶ˆæ¯æ˜¯æˆ‘ä»¬è¾“å…¥çš„å†…å®¹ã€‚è§’è‰²ä¸º LLM æä¾›äº†å¯¹è¿›è¡Œä¸­çš„å¯¹è¯çš„æ›´å¥½çš„ä¸Šä¸‹æ–‡ã€‚

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701190514.png")

æ¨¡å‹å’Œæç¤ºéƒ½å¾ˆé…·ï¼Œæ ‡å‡†åŒ–äº†ã€‚

## ç´¢å¼•ï¼ˆindexesï¼‰
ä½†æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„æ•°æ®å‘¢ï¼Ÿè¿™å°±æ˜¯ç´¢å¼•æ¨¡å—æ´¾ä¸Šç”¨åœºçš„åœ°æ–¹ã€‚

> æ•°æ®å°±æ˜¯æ–°çš„çŸ³æ²¹ï¼Œä½ è‚¯å®šå¯ä»¥åœ¨ä»»ä½•åœ°æ–¹æŒ–æ˜ï¼Œå¹¶æ‰¾åˆ°å¤§é‡çš„ã€‚

Langchain æä¾›äº†é’»æœºï¼Œé€šè¿‡æä¾›æ–‡æ¡£åŠ è½½å™¨ï¼Œæ–‡æ¡£æ˜¯ä»–ä»¬è¯´çš„æ–‡æœ¬çš„èŠ±å“¨æ–¹å¼ã€‚æœ‰å¾ˆå¤šæ”¯æŒçš„æ ¼å¼å’ŒæœåŠ¡ï¼Œæ¯”å¦‚ CSVã€ç”µå­é‚®ä»¶ã€SQLã€Discordã€AWS S3ã€PDFï¼Œç­‰ç­‰ã€‚å®ƒåªéœ€è¦ä¸‰è¡Œä»£ç å°±å¯ä»¥å¯¼å…¥ä½ çš„ã€‚è¿™å°±æ˜¯å®ƒæœ‰å¤šç®€å•!

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181943.png")


é¦–å…ˆå¯¼å…¥åŠ è½½å™¨ï¼Œç„¶åæŒ‡å®šæ–‡ä»¶è·¯å¾„ï¼Œç„¶åè°ƒç”¨ load æ–¹æ³•ã€‚è¿™å°†åœ¨å†…å­˜ä¸­ä»¥æ–‡æœ¬å½¢å¼åŠ è½½ PDFï¼Œä½œä¸ºä¸€ä¸ªæ•°ç»„ï¼Œå…¶ä¸­æ¯ä¸ªç´¢å¼•ä»£è¡¨ä¸€ä¸ªé¡µé¢ã€‚


### æ–‡æœ¬åˆ†å‰²å™¨ ï¼ˆtext_splitterï¼‰

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181957.png")

è¿™å¾ˆå¥½ï¼Œä½†æ˜¯å½“æˆ‘ä»¬æƒ³æ„å»ºä¸€ä¸ªæç¤ºå¹¶åŒ…å«è¿™äº›é¡µé¢ä¸­çš„æ–‡æœ¬æ—¶ï¼Œå®ƒä»¬å¯èƒ½å¤ªå¤§ï¼Œæ— æ³•åœ¨æˆ‘ä»¬ä¹‹å‰è°ˆè¿‡çš„è¾“å…¥ä»¤ç‰Œå¤§å°å†…é€‚åº”ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬æƒ³ä½¿ç”¨æ–‡æœ¬åˆ†å‰²å™¨å°†å®ƒä»¬åˆ‡æˆå—ã€‚


è¯»å®Œæ–‡æœ¬åï¼Œæˆ‘ä»¬å¯ä»¥å®ä¾‹åŒ–ä¸€ä¸ªé€’å½’å­—ç¬¦æ–‡æœ¬åˆ†å‰²å™¨ `RecursiveCharacterTextSplitter`ï¼Œå¹¶æŒ‡å®šä¸€ä¸ªå—å¤§å°å’Œä¸€ä¸ªå—é‡å ã€‚æˆ‘ä»¬è°ƒç”¨ `create_documents` æ–¹æ³•ï¼Œå¹¶å°†æˆ‘ä»¬çš„æ–‡æœ¬ä½œä¸ºå‚æ•°ã€‚

ç„¶åæˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªæ–‡æ¡£çš„æ•°ç»„ã€‚

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter


with open("example_data/state_of_the_union.txt") as f:
    state_of_the_union = f.read()

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=100,
    chunk_overlap=20,
)
texts = text_splitter.create_documents([state_of_the_union])
print(f"\nFirst chunk: {texts[0]}\n")
print(f"Second chunk: {texts[1]}\n")
```

ç°åœ¨æˆ‘ä»¬æœ‰äº†æ–‡æœ¬å—ï¼Œæˆ‘ä»¬ä¼šæƒ³è¦åµŒå…¥å®ƒä»¬å¹¶å­˜å‚¨å®ƒä»¬ï¼Œä»¥ä¾¿æœ€ç»ˆä½¿ç”¨è¯­ä¹‰æœç´¢æ£€ç´¢å®ƒä»¬ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬æœ‰å‘é‡å­˜å‚¨ã€‚

### ä¸å‘é‡æ•°æ®åº“çš„é›†æˆ

ç´¢å¼•æ¨¡å—çš„è¿™ä¸€éƒ¨åˆ†æä¾›äº†å¤šä¸ªä¸å‘é‡æ•°æ®åº“çš„é›†æˆï¼Œå¦‚ pine coneã€redisã€Super Bassã€chroma DB ç­‰ç­‰ã€‚

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701182104.png")

### å‘é‡ç©ºé—´ä¸­è¿›è¡Œæœç´¢

ä¸€æ—¦ä½ å‡†å¤‡å¥½äº†ä½ çš„æ–‡æ¡£ï¼Œä½ å°±ä¼šæƒ³é€‰æ‹©ä½ çš„åµŒå…¥æä¾›å•†ï¼Œå¹¶ä½¿ç”¨å‘é‡æ•°æ®åº“åŠ©æ‰‹æ–¹æ³•å­˜å‚¨æ–‡æ¡£ã€‚

ç°åœ¨æˆ‘ä»¬å¯ä»¥å†™ä¸€ä¸ªé—®é¢˜ï¼Œåœ¨å‘é‡ç©ºé—´ä¸­è¿›è¡Œæœç´¢ï¼Œæ‰¾å‡ºæœ€ç›¸ä¼¼çš„ç»“æœ `similarity_search`ï¼Œè¿”å›å®ƒä»¬çš„æ–‡æœ¬ã€‚

```python
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma


with open("example_data/state_of_the_union.txt") as f:
    state_of_the_union = f.read()

text_splitter = CharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=0,
)
texts = text_splitter.create_documents([state_of_the_union])

embeddings = OpenAIEmbeddings()
docsearch = Chroma.from_texts(texts, embeddings)

query = "What did the president say about Ketanji Brown Jackson"
docs = docsearch.similarity_search(query)


print(docs[0].page_content)
```

![]("D:\liteli\chatGPT\langchainå‡ºä¹¦\çŸ¥ä¹\langchain101\å¾®ä¿¡æˆªå›¾_20230701181957.png")

ä»æ„å»ºæç¤ºåˆ°ç´¢å¼•æ–‡æ¡£ï¼Œå†åˆ°åœ¨å‘é‡ç©ºé—´ä¸­è¿›è¡Œæœç´¢ï¼Œéƒ½å¯ä»¥é€šè¿‡å¯¼å…¥ä¸€ä¸ªæ¨¡å—å¹¶è¿è¡Œå‡ è¡Œä»£ç æ¥å®Œæˆã€‚

å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªæ—…ç¨‹ï¼Œè®©æˆ‘ä»¬å¼€å§‹æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººä¹‹æ—…å§ï¼

å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–æƒ³è¦æŸ¥çœ‹æ›´è¯¦ç»†çš„å®ä¾‹ï¼Œä½ å¯ä»¥åœ¨åŠ å…¥ç¤¾ç¾¤æé—®ã€‚æˆ‘æœŸå¾…ç€ä½ çš„åé¦ˆå’Œä½ åœ¨ç¤¾åŒºä¸­åˆ†äº«çš„ä»»ä½•åˆ›æ–°ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä¸€èµ·åˆ›é€ æœªæ¥ï¼


ğŸ”— Links
Source code: https://github.com/edrickdch/langchain-101
LangChain: https://python.langchain.com.cn
Self-Ask Paper: https://ofir.io/self-ask.pdf 
ReAct Paper: https://arxiv.org/abs/2210.03629